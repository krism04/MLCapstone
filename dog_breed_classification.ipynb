{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-15T05:57:28.226707Z",
     "iopub.status.busy": "2025-10-15T05:57:28.226299Z",
     "iopub.status.idle": "2025-10-15T05:57:39.751549Z",
     "shell.execute_reply": "2025-10-15T05:57:39.750483Z",
     "shell.execute_reply.started": "2025-10-15T05:57:28.226653Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Note: The exact path might vary slightly depending on the Kaggle environment.\n",
    "# This path is a common structure for this dataset.\n",
    "train_dir = \"/kaggle/input/stanford-dogs-dataset/images/Images\"\n",
    "# The Stanford Dogs dataset, as provided in the link, doesn't have a separate test directory in the same format.\n",
    "# We will create train and validation sets from the main directory.\n",
    "# If you have a separate 'test' directory, you can uncomment the next line and adjust the code.\n",
    "\n",
    "\n",
    "tf= transforms.Compose([transforms.Resize((256,256)),\n",
    "                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                       transforms.RandomVerticalFlip(p=0.5),\n",
    "                       transforms.RandomRotation((10,40)),\n",
    "                       transforms.ToTensor()])\n",
    "\n",
    "\n",
    "# Create the full dataset from the main directory\n",
    "full_dataset = ImageFolder(train_dir, transform=tf) #an array of images\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.6 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# If you have a separate test set, you would load it like this:\n",
    "# test_dataset = ImageFolder(test_dir, transform=tf)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"Length of train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T05:57:39.753829Z",
     "iopub.status.busy": "2025-10-15T05:57:39.753362Z",
     "iopub.status.idle": "2025-10-15T05:57:39.758687Z",
     "shell.execute_reply": "2025-10-15T05:57:39.757585Z",
     "shell.execute_reply.started": "2025-10-15T05:57:39.753804Z"
    }
   },
   "outputs": [],
   "source": [
    "#image, label = train_dataset[2001]\n",
    "\n",
    "#print(f\"Label: {label}\")\n",
    "\n",
    "#plt.imshow(image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T05:57:39.760107Z",
     "iopub.status.busy": "2025-10-15T05:57:39.759738Z",
     "iopub.status.idle": "2025-10-15T05:57:39.780801Z",
     "shell.execute_reply": "2025-10-15T05:57:39.77986Z",
     "shell.execute_reply.started": "2025-10-15T05:57:39.760073Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=120):\n",
    "        super().__init__()\n",
    "    # Conv Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1) #32, 256, 256\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #32, 128, 128\n",
    "        self.drop1 = nn.Dropout(p=0.1)\n",
    "        # Conv Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1) #64,128, 128\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #64, 64, 64 \n",
    "        self.drop2 = nn.Dropout(p=0.1)\n",
    "        # Conv Block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1) #128, 64, 64\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2) #128, 32, 32\n",
    "        self.drop3 = nn.Dropout(p=0.1)\n",
    "        # Conv Block 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) #256, 32, 32\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2) #256, 16, 16\n",
    "        self.drop4 = nn.Dropout(p=0.1)\n",
    "    \n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))  #256, 1, 1\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(256, num_classes) # Fully-Connected/MLP/Linear Layer #10\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Block 1 Output\n",
    "        x = self.drop1(self.pool1(self.bn1(self.conv1(x))))\n",
    "        # Block 2 Output\n",
    "        x = self.drop2(self.pool2(self.bn2(self.conv2(x))))\n",
    "        # Block 3 Output\n",
    "        x = self.drop3(self.pool3(self.bn3(self.conv3(x))))\n",
    "        # Block 4 Output\n",
    "        x = self.drop4(self.pool4(self.bn4(self.conv4(x))))\n",
    "        # Classification Head\n",
    "        x = self.fc(self.flatten(self.gap(x)))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T05:57:39.782273Z",
     "iopub.status.busy": "2025-10-15T05:57:39.781995Z",
     "iopub.status.idle": "2025-10-15T05:57:39.825725Z",
     "shell.execute_reply": "2025-10-15T05:57:39.824813Z",
     "shell.execute_reply.started": "2025-10-15T05:57:39.782252Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T05:57:39.82853Z",
     "iopub.status.busy": "2025-10-15T05:57:39.827855Z",
     "iopub.status.idle": "2025-10-15T05:57:39.838447Z",
     "shell.execute_reply": "2025-10-15T05:57:39.837313Z",
     "shell.execute_reply.started": "2025-10-15T05:57:39.828501Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    preds = outputs.argmax(dim=1)   # 32, 10  #airplane =0.6 (argmax pick this), cat =0.2, dog = 0.1, deer =0.05,...\n",
    "    acc = (preds == labels).float().mean().item()  # 24 correct, total= 32, avg=24/32=0.75 (mean) [0 1 2 5] == [1 1 2 1] = [0 1 1 0] avg(0.5)\n",
    "    return acc\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=100):\n",
    "    for i in range(num_epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        train_acc_sum = 0.0\n",
    "        train_samples = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()    # dl/dW\n",
    "            optimizer.step()  #W< W-lr*dl/dW \n",
    "            running_train_loss += loss.item() * images.size(0) # 32, 3, 256, 256\n",
    "            train_acc_sum += accuracy(outputs, labels) * images.size(0)\n",
    "            train_samples += images.size(0)\n",
    "\n",
    "        epoch_train_loss = running_train_loss/train_samples\n",
    "        epoch_train_acc = train_acc_sum/train_samples\n",
    "\n",
    "        # validation\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        val_acc_sum = 0.0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            running_val_loss += loss.item() * images.size(0) # 32, 3, 256, 256\n",
    "            val_acc_sum += accuracy(outputs, labels) * images.size(0)\n",
    "            val_samples += images.size(0)\n",
    "\n",
    "        epoch_val_loss = running_val_loss/val_samples\n",
    "        epoch_val_acc = val_acc_sum/val_samples\n",
    "        \n",
    "        print(f\"Epoch: {i}, train_loss: {epoch_train_loss}, train_acc: {epoch_train_acc}, val_loss{epoch_val_loss}, val_acc: {epoch_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-15T05:58:27.624Z",
     "iopub.execute_input": "2025-10-15T05:57:39.840021Z",
     "iopub.status.busy": "2025-10-15T05:57:39.839517Z"
    }
   },
   "outputs": [],
   "source": [
    "train_model(model1, criterion, optimizer, train_loader, val_loader, device, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-15T05:58:27.624Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, test_loader, device):\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        test_acc_sum = 0.0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            running_test_loss += loss.item() * images.size(0) # 32, 3, 256, 256\n",
    "            test_acc_sum += accuracy(outputs, labels) * images.size(0)\n",
    "            test_samples += images.size(0)\n",
    "\n",
    "        epoch_test_loss = running_test_loss/test_samples\n",
    "        epoch_test_acc = test_acc_sum/test_samples\n",
    "    \n",
    "        print(f\"test_loss: {epoch_test_loss}, test_acc: {epoch_test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-15T05:58:27.624Z"
    }
   },
   "outputs": [],
   "source": [
    "test_model(model1, criterion, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 119698,
     "sourceId": 791828,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CS4CMDA",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
